#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
UR5e Hand-Eye (eye-in-hand) with ChArUco + OpenCV
- Online capture (ROS2): show camera image, press 's' to save image + joint_states
  and (best-effort) TF base->tool as a 4x4 matrix.
- Offline hand-eye: estimate T_gripper_cam using cv2.calibrateHandEye.

Board (from your calib.io image):
- squares_x x squares_y: 8 x 11
- square length: 15 mm
- marker length: 11 mm
- Dictionary: "AruCo DICT_4X4" (OpenCV requires one of DICT_4X4_{50,100,250,1000})
  => This script auto-tries all 4x4 dictionaries and locks the best one.

Your intrinsics file (ost.yaml) is ROS camera_calibration format:
camera_matrix:
  rows: 3
  cols: 3
  data: [...]
distortion_coefficients:
  rows: 1
  cols: 5
  data: [...]

This script supports it directly.

Data layout (auto-created under output_dir):
output_dir/
  images/
    000001.png
    000002.png
    ...
  samples.json        # each 's' press appends one sample
  handeye_result.yaml # generated by 'handeye' subcommand

ROS2 topics:
- image_topic: sensor_msgs/Image
- joint_topic: sensor_msgs/JointState
- TF: base_frame -> tool_frame (recommended: base_link -> tool0)
"""

import argparse
import json
import os
from pathlib import Path
from typing import Optional, Any, Tuple

import numpy as np
import cv2
import yaml

import rclpy
from rclpy.node import Node
from rclpy.time import Time
from sensor_msgs.msg import Image, JointState
from cv_bridge import CvBridge

import tf2_ros
from geometry_msgs.msg import TransformStamped


# -------------------------- Math utils --------------------------

def _as_np(x, shape=None, dtype=np.float64):
    arr = np.array(x, dtype=dtype)
    if shape is not None:
        arr = arr.reshape(shape)
    return arr

def make_T(R, t):
    T = np.eye(4, dtype=np.float64)
    T[:3, :3] = _as_np(R, (3, 3))
    T[:3, 3] = _as_np(t, (3,))
    return T

def rodrigues_to_R(rvec):
    rvec = _as_np(rvec, (3, 1))
    R, _ = cv2.Rodrigues(rvec)
    return R

def R_to_rodrigues(R):
    rvec, _ = cv2.Rodrigues(_as_np(R, (3, 3)))
    return rvec

def transform_to_T(tf: TransformStamped) -> np.ndarray:
    t = tf.transform.translation
    q = tf.transform.rotation
    x, y, z, w = q.x, q.y, q.z, q.w
    n = np.sqrt(x*x + y*y + z*z + w*w)
    if n < 1e-12:
        raise ValueError("Quaternion norm too small in TF.")
    x, y, z, w = x/n, y/n, z/n, w/n
    R = np.array([
        [1 - 2*(y*y + z*z),     2*(x*y - z*w),       2*(x*z + y*w)],
        [2*(x*y + z*w),         1 - 2*(x*x + z*z),   2*(y*z - x*w)],
        [2*(x*z - y*w),         2*(y*z + x*w),       1 - 2*(x*x + y*y)]
    ], dtype=np.float64)
    return make_T(R, np.array([t.x, t.y, t.z], dtype=np.float64))


# -------------------------- I/O utils --------------------------

def atomic_write_json(path: Path, data: Any):
    path.parent.mkdir(parents=True, exist_ok=True)
    tmp = path.with_suffix(path.suffix + ".tmp")
    with open(tmp, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2)
    os.replace(tmp, path)

def load_json_if_exists(path: Path, default: Any):
    if not path.exists():
        return default
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def _extract_matrix_field(field: Any, expect_rows: int, expect_cols: int, name: str) -> np.ndarray:
    """
    Supports:
      1) flat list length rows*cols
      2) nested list [[...], ...]
      3) ROS camera_calibration dict: {rows, cols, data:[...]}
    """
    if field is None:
        raise KeyError(f"Missing field: {name}")

    if isinstance(field, dict) and "data" in field:
        rows = int(field.get("rows", expect_rows))
        cols = int(field.get("cols", expect_cols))
        data = field["data"]
        arr = np.array(data, dtype=np.float64).reshape(rows, cols)
        if rows != expect_rows or cols != expect_cols:
            raise ValueError(f"{name} shape mismatch: got {rows}x{cols}, expected {expect_rows}x{expect_cols}")
        return arr

    arr = np.array(field, dtype=np.float64)
    if arr.ndim == 1:
        arr = arr.reshape(expect_rows, expect_cols)
    else:
        arr = arr.reshape(expect_rows, expect_cols)
    return arr

def _extract_vector_field(field: Any, expect_len: int, name: str) -> np.ndarray:
    """
    Supports:
      1) list length N
      2) ROS camera_calibration dict: {rows, cols, data:[...]}
    Returns (N,1)
    """
    if field is None:
        raise KeyError(f"Missing field: {name}")

    if isinstance(field, dict) and "data" in field:
        data = field["data"]
        vec = np.array(data, dtype=np.float64).reshape(-1)
    else:
        vec = np.array(field, dtype=np.float64).reshape(-1)

    if vec.size < expect_len:
        raise ValueError(f"{name} length too short: got {vec.size}, expected >= {expect_len}")

    vec = vec[:expect_len].reshape(expect_len, 1)
    return vec

def load_intrinsics_yaml(path: Path):
    """
    Compatible with:
    - ROS camera_calibration YAML (your ost.yaml):
        camera_matrix: {rows:3, cols:3, data:[...]}
        distortion_coefficients: {rows:1, cols:5, data:[...]}
    - Simplified YAML:
        camera_matrix: [[...],[...],[...]]
        dist_coeffs: [...]
    """
    with open(path, "r", encoding="utf-8") as f:
        data = yaml.safe_load(f)

    # K
    if "camera_matrix" in data:
        K = _extract_matrix_field(data["camera_matrix"], 3, 3, "camera_matrix")
    elif "K" in data:
        K = _extract_matrix_field(data["K"], 3, 3, "K")
    else:
        raise KeyError("Intrinsics YAML must contain 'camera_matrix' or 'K'.")

    # Distortion
    dist_field = None
    if "distortion_coefficients" in data:
        dist_field = data["distortion_coefficients"]
    elif "dist_coeffs" in data:
        dist_field = data["dist_coeffs"]
    elif "dist" in data:
        dist_field = data["dist"]
    elif "distortion" in data:
        dist_field = data["distortion"]

    if dist_field is None:
        dist = np.zeros((5, 1), dtype=np.float64)
    else:
        dist = _extract_vector_field(dist_field, 5, "distortion_coefficients")

    return K, dist


# -------------------------- ChArUco helpers --------------------------

DICT_4X4_CANDIDATES = [
    ("DICT_4X4_50", cv2.aruco.DICT_4X4_50),
    ("DICT_4X4_100", cv2.aruco.DICT_4X4_100),
    ("DICT_4X4_250", cv2.aruco.DICT_4X4_250),
    ("DICT_4X4_1000", cv2.aruco.DICT_4X4_1000),
]

def build_charuco(board_squares_x: int, board_squares_y: int,
                  square_length_m: float, marker_length_m: float,
                  dict_id: int):
    dictionary = cv2.aruco.getPredefinedDictionary(dict_id)

    # Charuco board: OpenCV 4.5.x uses CharucoBoard_create
    if hasattr(cv2.aruco, "CharucoBoard_create"):
        board = cv2.aruco.CharucoBoard_create(
            int(board_squares_x), int(board_squares_y),
            float(square_length_m), float(marker_length_m),
            dictionary
        )
    else:
        # Newer OpenCV may expose CharucoBoard class
        board = cv2.aruco.CharucoBoard(
            (int(board_squares_x), int(board_squares_y)),
            float(square_length_m), float(marker_length_m),
            dictionary
        )

    # Detector parameters: OpenCV 4.5.x uses DetectorParameters_create()
    if hasattr(cv2.aruco, "DetectorParameters_create"):
        params = cv2.aruco.DetectorParameters_create()
    else:
        params = cv2.aruco.DetectorParameters()

    # ArucoDetector exists only in newer OpenCV; keep None for 4.5.x
    detector = None
    if hasattr(cv2.aruco, "ArucoDetector"):
        detector = cv2.aruco.ArucoDetector(dictionary, params)

    return dictionary, board, detector, params


def detect_markers(gray: np.ndarray, dictionary, detector, params):
    # Newer OpenCV path
    if detector is not None:
        corners, ids, rejected = detector.detectMarkers(gray)
    else:
        # OpenCV 4.5.x path
        corners, ids, rejected = cv2.aruco.detectMarkers(gray, dictionary, parameters=params)

    n = 0 if ids is None else len(ids)
    return corners, ids, rejected, n


def detect_markers(gray: np.ndarray, dictionary, detector, params):
    if detector is not None:
        corners, ids, rejected = detector.detectMarkers(gray)
    else:
        corners, ids, rejected = cv2.aruco.detectMarkers(gray, dictionary, parameters=params)
    n = 0 if ids is None else len(ids)
    return corners, ids, rejected, n

def auto_pick_4x4_dictionary(gray: np.ndarray,
                            board_squares_x: int, board_squares_y: int,
                            square_length_m: float, marker_length_m: float) -> Tuple[str, int]:
    best_name, best_id = DICT_4X4_CANDIDATES[0]
    best_n = -1
    for name, did in DICT_4X4_CANDIDATES:
        dictionary, board, detector, params = build_charuco(
            board_squares_x, board_squares_y, square_length_m, marker_length_m, did
        )
        _, _, _, n = detect_markers(gray, dictionary, detector, params)
        if n > best_n:
            best_n = n
            best_name, best_id = name, did
    return best_name, best_id

def detect_charuco_pose(bgr: np.ndarray,
                        board_squares_x: int, board_squares_y: int,
                        square_length_m: float, marker_length_m: float,
                        dict_id: int,
                        K: Optional[np.ndarray] = None,
                        dist: Optional[np.ndarray] = None,
                        min_charuco_corners: int = 10,
                        draw: bool = True):
    """
    Compatible across OpenCV builds:
    - If cv2.aruco.interpolateCornersCharuco exists: use Charuco interpolation + estimatePoseCharucoBoard
    - Else: fallback to marker-only pose via estimatePoseBoard (uses ArUco marker corners only)

    Returns:
      ok_pose, rvec, tvec, dbg, n_markers, n_charuco
    """
    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)
    dictionary, board, detector, params = build_charuco(
        board_squares_x, board_squares_y, square_length_m, marker_length_m, dict_id
    )

    # Detect markers
    if detector is not None:
        corners, ids, rejected = detector.detectMarkers(gray)
    else:
        corners, ids, rejected = cv2.aruco.detectMarkers(gray, dictionary, parameters=params)

    n_markers = 0 if ids is None else len(ids)
    dbg = bgr.copy() if draw else None

    if ids is None or len(ids) < 4:
        return False, None, None, dbg, n_markers, 0

    ids = np.asarray(ids, dtype=np.int32)

    # Draw markers
    if draw and dbg is not None:
        cv2.aruco.drawDetectedMarkers(dbg, corners, ids)

    # If no intrinsics, we cannot estimate pose
    if K is None or dist is None:
        return False, None, None, dbg, n_markers, 0

    has_charuco_interp = hasattr(cv2.aruco, "interpolateCornersCharuco")
    has_charuco_pose = hasattr(cv2.aruco, "estimatePoseCharucoBoard")
    has_board_pose = hasattr(cv2.aruco, "estimatePoseBoard")

    # ------------------ Path A: Charuco (if available) ------------------
    if has_charuco_interp and has_charuco_pose:
        try:
            # positional args for compatibility
            retval, charuco_corners, charuco_ids = cv2.aruco.interpolateCornersCharuco(
                corners, ids, gray, board, K, dist
            )
        except TypeError:
            # some builds accept only 4 args
            retval, charuco_corners, charuco_ids = cv2.aruco.interpolateCornersCharuco(
                corners, ids, gray, board
            )

        n_charuco = 0 if charuco_ids is None else int(retval)

        if draw and dbg is not None and charuco_corners is not None and charuco_ids is not None:
            if hasattr(cv2.aruco, "drawDetectedCornersCharuco"):
                cv2.aruco.drawDetectedCornersCharuco(dbg, charuco_corners, charuco_ids, (0, 255, 0))

        if charuco_ids is None or charuco_corners is None or n_charuco < int(min_charuco_corners):
            return False, None, None, dbg, n_markers, n_charuco

        try:
            ok, rvec, tvec = cv2.aruco.estimatePoseCharucoBoard(
                charuco_corners, charuco_ids, board, K, dist, None, None
            )
        except TypeError:
            ok, rvec, tvec = cv2.aruco.estimatePoseCharucoBoard(
                charuco_corners, charuco_ids, board, K, dist
            )

        if draw and dbg is not None and ok:
            cv2.drawFrameAxes(dbg, K, dist, rvec, tvec, 0.05)

        return bool(ok), rvec, tvec, dbg, n_markers, n_charuco

    # ------------------ Path B: Marker-only board pose fallback ------------------
    if not has_board_pose:
        # Your OpenCV is missing both Charuco and estimatePoseBoard => must install opencv-contrib-python
        raise RuntimeError(
            "Your OpenCV build lacks Charuco APIs AND cv2.aruco.estimatePoseBoard. "
            "Please install opencv-contrib-python in your current Python environment."
        )

    # estimatePoseBoard uses marker corners only (works without Charuco functions)
    try:
        ok, rvec, tvec = cv2.aruco.estimatePoseBoard(
            corners, ids, board, K, dist, None, None
        )
    except TypeError:
        ok, rvec, tvec = cv2.aruco.estimatePoseBoard(
            corners, ids, board, K, dist
        )

    if draw and dbg is not None and ok:
        cv2.drawFrameAxes(dbg, K, dist, rvec, tvec, 0.05)

    # n_charuco=0 indicates we're in marker-only mode
    return bool(ok), rvec, tvec, dbg, n_markers, 0


# -------------------------- ROS2 Capture Node --------------------------

class CaptureNode(Node):
    def __init__(self, args):
        super().__init__("ur5e_charuco_handeye_capture")
        self.args = args
        self.bridge = CvBridge()

        self.output_dir = Path(args.output_dir)
        self.images_dir = self.output_dir / "images"
        self.images_dir.mkdir(parents=True, exist_ok=True)
        self.samples_path = self.output_dir / "samples.json"

        self.samples = load_json_if_exists(self.samples_path, {"samples": []})
        if "samples" not in self.samples:
            self.samples = {"samples": []}

        self.latest_bgr = None
        self.latest_img_msg = None
        self.latest_joint = None

        self.K = None
        self.dist = None
        if args.intrinsics_yaml:
            self.K, self.dist = load_intrinsics_yaml(Path(args.intrinsics_yaml))
            self.get_logger().info(f"Loaded intrinsics: {args.intrinsics_yaml}")
        else:
            self.get_logger().warn("No intrinsics provided. Pose axis will not be estimated/drawn.")

        self.tf_buffer = tf2_ros.Buffer(cache_time=rclpy.duration.Duration(seconds=10.0))
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)

        self.create_subscription(Image, args.image_topic, self.on_image, 10)
        self.create_subscription(JointState, args.joint_topic, self.on_joint, 50)

        self.squares_x = int(args.squares_x)
        self.squares_y = int(args.squares_y)
        self.square_length_m = float(args.square_mm) / 1000.0
        self.marker_length_m = float(args.marker_mm) / 1000.0
        self.min_charuco_corners = int(args.min_charuco_corners)

        self.dict_locked_name = None
        self.dict_locked_id = None
        self.dict_lock_after = int(args.dict_lock_after)
        self.dict_seen_frames = 0

        self.window_name = "UR5e HandEye Capture (press 's' to save, 'q' to quit)"
        cv2.namedWindow(self.window_name, cv2.WINDOW_NORMAL)
        self.timer = self.create_timer(0.03, self.on_timer)

        self.get_logger().info("Capture node started.")
        self.get_logger().info(f"Image topic: {args.image_topic}")
        self.get_logger().info(f"Joint topic: {args.joint_topic}")
        self.get_logger().info(f"TF base->tool: {args.base_frame} -> {args.tool_frame}")
        self.get_logger().info(f"Output dir: {self.output_dir}")

    def on_image(self, msg: Image):
        try:
            bgr = self.bridge.imgmsg_to_cv2(msg, desired_encoding="bgr8")
        except Exception as e:
            self.get_logger().error(f"cv_bridge failed: {e}")
            return
        self.latest_bgr = bgr
        self.latest_img_msg = msg

    def on_joint(self, msg: JointState):
        self.latest_joint = msg

    def _maybe_lock_dict(self, gray: np.ndarray):
        if self.dict_locked_id is not None:
            return
        name, did = auto_pick_4x4_dictionary(
            gray, self.squares_x, self.squares_y, self.square_length_m, self.marker_length_m
        )
        self.dict_seen_frames += 1
        if self.dict_seen_frames >= self.dict_lock_after:
            self.dict_locked_name = name
            self.dict_locked_id = did
            self.get_logger().info(f"Locked ArUco dictionary to: {name}")

    def _lookup_base_tool_T(self, stamp_ros: Time) -> Optional[np.ndarray]:
        # 1) try exact stamp
        try:
            tf = self.tf_buffer.lookup_transform(
                self.args.base_frame, self.args.tool_frame,
                stamp_ros,
                timeout=rclpy.duration.Duration(seconds=0.2)
            )
            return transform_to_T(tf)
        except Exception:
            pass

        # 2) fallback to latest available
        try:
            tf = self.tf_buffer.lookup_transform(
                self.args.base_frame, self.args.tool_frame,
                Time(),  # latest
                timeout=rclpy.duration.Duration(seconds=0.2)
            )
            return transform_to_T(tf)
        except Exception:
            return None


    def _save_sample(self):
        if self.latest_bgr is None or self.latest_img_msg is None:
            self.get_logger().warn("No image yet; cannot save.")
            return
        if self.latest_joint is None:
            self.get_logger().warn("No joint_states yet; cannot save.")
            return

        idx = len(self.samples["samples"]) + 1
        img_name = f"{idx:06d}.png"
        img_path = self.images_dir / img_name

        ok = cv2.imwrite(str(img_path), self.latest_bgr)
        if not ok:
            self.get_logger().error(f"Failed to write image: {img_path}")
            return

        stamp = self.latest_img_msg.header.stamp
        stamp_ros = Time(seconds=int(stamp.sec), nanoseconds=int(stamp.nanosec))
        T_base_tool = self._lookup_base_tool_T(stamp_ros)

        js = self.latest_joint
        sample = {
            "image": img_name,
            "stamp": {"sec": int(stamp.sec), "nanosec": int(stamp.nanosec)},
            "joint_state": {
                "name": list(js.name),
                "position": [float(x) for x in js.position],
                "velocity": [float(x) for x in js.velocity] if len(js.velocity) else [],
                "effort": [float(x) for x in js.effort] if len(js.effort) else [],
            },
            "frames": {"base": self.args.base_frame, "tool": self.args.tool_frame},
            "T_base_tool": T_base_tool.tolist() if T_base_tool is not None else None
        }

        self.samples["samples"].append(sample)
        atomic_write_json(self.samples_path, self.samples)

        self.get_logger().info(
            f"Saved sample #{idx}: image={img_name}, "
            f"T_base_tool={'OK' if T_base_tool is not None else 'None'}"
        )

    def on_timer(self):
        if self.latest_bgr is None:
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                rclpy.shutdown()
            return

        bgr = self.latest_bgr.copy()
        gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)

        self._maybe_lock_dict(gray)
        dict_name = self.dict_locked_name if self.dict_locked_name else "AUTO(trying 4x4)"
        if self.dict_locked_id is None:
            _, dict_id = auto_pick_4x4_dictionary(
                gray, self.squares_x, self.squares_y, self.square_length_m, self.marker_length_m
            )
        else:
            dict_id = self.dict_locked_id

        ok_pose, rvec, tvec, dbg, n_markers, n_charuco = detect_charuco_pose(
            bgr=bgr,
            board_squares_x=self.squares_x,
            board_squares_y=self.squares_y,
            square_length_m=self.square_length_m,
            marker_length_m=self.marker_length_m,
            dict_id=dict_id,
            K=self.K,
            dist=self.dist,
            min_charuco_corners=self.min_charuco_corners,
            draw=True
        )

        if dbg is None:
            dbg = bgr

        line1 = f"samples={len(self.samples['samples'])}  dict={dict_name}"
        line2 = f"markers={n_markers}  charuco={n_charuco}  pose={'OK' if ok_pose else 'NO'}"
        line3 = f"image={'OK' if self.latest_img_msg else 'NO'}  joint={'OK' if self.latest_joint else 'NO'}"
        cv2.putText(dbg, line1, (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (20, 20, 20), 3, cv2.LINE_AA)
        cv2.putText(dbg, line1, (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (240, 240, 240), 1, cv2.LINE_AA)
        cv2.putText(dbg, line2, (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (20, 20, 20), 3, cv2.LINE_AA)
        cv2.putText(dbg, line2, (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (240, 240, 240), 1, cv2.LINE_AA)
        cv2.putText(dbg, line3, (20, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (20, 20, 20), 3, cv2.LINE_AA)
        cv2.putText(dbg, line3, (20, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (240, 240, 240), 1, cv2.LINE_AA)

        cv2.imshow(self.window_name, dbg)
        key = cv2.waitKey(1) & 0xFF
        if key == ord('s'):
            self._save_sample()
        elif key == ord('q'):
            rclpy.shutdown()


# -------------------------- Offline hand-eye --------------------------

def handeye_method_from_string(s: str):
    s = s.strip().lower()
    mapping = {
        "tsai": cv2.CALIB_HAND_EYE_TSAI,
        "park": cv2.CALIB_HAND_EYE_PARK,
        "horaud": cv2.CALIB_HAND_EYE_HORAUD,
        "andreff": cv2.CALIB_HAND_EYE_ANDREFF,
        "daniilidis": cv2.CALIB_HAND_EYE_DANIILIDIS,
    }
    if s not in mapping:
        raise ValueError(f"Unsupported method '{s}', choose from {list(mapping.keys())}")
    return mapping[s]

def run_handeye_offline(output_dir: Path,
                        intrinsics_yaml: Path,
                        squares_x: int, squares_y: int,
                        square_mm: float, marker_mm: float,
                        min_charuco_corners: int,
                        method: str,
                        dict_mode: str = "auto_4x4"):
    images_dir = output_dir / "images"
    samples_path = output_dir / "samples.json"
    if not samples_path.exists():
        raise FileNotFoundError(f"Missing: {samples_path}")

    data = load_json_if_exists(samples_path, {"samples": []})
    samples = data.get("samples", [])
    if len(samples) < 8:
        raise RuntimeError(f"Too few samples: {len(samples)}. 建议至少 15-30 组更稳。")

    K, dist = load_intrinsics_yaml(intrinsics_yaml)

    square_length_m = float(square_mm) / 1000.0
    marker_length_m = float(marker_mm) / 1000.0

    R_gripper2base, t_gripper2base = [], []
    R_target2cam, t_target2cam = [], []

    used, skipped = 0, 0
    dict_locked_id, dict_locked_name = None, None

    name_to_id = {n: did for n, did in DICT_4X4_CANDIDATES}

    for s in samples:
        img_name = s.get("image", None)
        T_base_tool = s.get("T_base_tool", None)
        if img_name is None or T_base_tool is None:
            skipped += 1
            continue

        img_path = images_dir / img_name
        bgr = cv2.imread(str(img_path), cv2.IMREAD_COLOR)
        if bgr is None:
            skipped += 1
            continue

        gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)

        if dict_mode == "auto_4x4":
            if dict_locked_id is None:
                dict_locked_name, dict_locked_id = auto_pick_4x4_dictionary(
                    gray, squares_x, squares_y, square_length_m, marker_length_m
                )
        else:
            if dict_mode not in name_to_id:
                raise ValueError(f"dict_mode must be 'auto_4x4' or one of {list(name_to_id.keys())}")
            dict_locked_name, dict_locked_id = dict_mode, name_to_id[dict_mode]

        ok, rvec, tvec, _, _, _ = detect_charuco_pose(
            bgr=bgr,
            board_squares_x=squares_x,
            board_squares_y=squares_y,
            square_length_m=square_length_m,
            marker_length_m=marker_length_m,
            dict_id=dict_locked_id,
            K=K,
            dist=dist,
            min_charuco_corners=min_charuco_corners,
            draw=False
        )
        if not ok:
            skipped += 1
            continue

        R_tc = rodrigues_to_R(rvec)
        t_tc = _as_np(tvec, (3, 1))

        T_base_tool = _as_np(T_base_tool, (4, 4))
        R_gb = T_base_tool[:3, :3]
        t_gb = T_base_tool[:3, 3].reshape(3, 1)

        R_gripper2base.append(R_gb)
        t_gripper2base.append(t_gb)
        R_target2cam.append(R_tc)
        t_target2cam.append(t_tc)
        used += 1

    if used < 8:
        raise RuntimeError(f"Valid handeye pairs too few: used={used}, skipped={skipped}.")

    method_id = handeye_method_from_string(method)
    R_cam2gripper, t_cam2gripper = cv2.calibrateHandEye(
        R_gripper2base=R_gripper2base,
        t_gripper2base=t_gripper2base,
        R_target2cam=R_target2cam,
        t_target2cam=t_target2cam,
        method=method_id
    )
    T_gripper_cam = make_T(R_cam2gripper, t_cam2gripper.reshape(3,))

    # Consistency: base_T_board should be constant
    T_base_board_list = []
    for i in range(used):
        T_base_tool_i = make_T(R_gripper2base[i], t_gripper2base[i].reshape(3,))
        T_cam_board_i = make_T(R_target2cam[i], t_target2cam[i].reshape(3,))
        T_base_board = T_base_tool_i @ T_gripper_cam @ T_cam_board_i
        T_base_board_list.append(T_base_board)

    Ts = np.stack(T_base_board_list, axis=0)
    t_mean = Ts[:, :3, 3].mean(axis=0)
    t_std = Ts[:, :3, 3].std(axis=0)

    Rm = Ts[:, :3, :3].mean(axis=0)
    U, _, Vt = np.linalg.svd(Rm)
    R_mean = U @ Vt
    angs = []
    for i in range(Ts.shape[0]):
        R_err = R_mean.T @ Ts[i, :3, :3]
        rvec_err = R_to_rodrigues(R_err)
        angs.append(float(np.linalg.norm(rvec_err)))
    ang_mean = float(np.mean(angs))
    ang_std = float(np.std(angs))

    result = {
        "used_pairs": int(used),
        "skipped": int(skipped),
        "dict_locked": dict_locked_name,
        "T_gripper_cam": T_gripper_cam.tolist(),
        "board_consistency": {
            "T_base_board_translation_mean_m": t_mean.tolist(),
            "T_base_board_translation_std_m": t_std.tolist(),
            "T_base_board_rotation_angle_mean_rad": ang_mean,
            "T_base_board_rotation_angle_std_rad": ang_std,
        },
        "board": {
            "squares_x": int(squares_x),
            "squares_y": int(squares_y),
            "square_mm": float(square_mm),
            "marker_mm": float(marker_mm),
            "min_charuco_corners": int(min_charuco_corners),
        },
        "method": method,
        "intrinsics_yaml": str(intrinsics_yaml),
    }

    out_path = output_dir / "handeye_result.yaml"
    with open(out_path, "w", encoding="utf-8") as f:
        yaml.safe_dump(result, f, sort_keys=False)

    print("=== Hand-eye done ===")
    print(f"used_pairs={used}, skipped={skipped}, dict={dict_locked_name}")
    print("T_gripper_cam=\n", np.array(T_gripper_cam))
    print("translation std (m) =", np.array(t_std))
    print("rotation angle std (rad) =", ang_std)
    print(f"saved: {out_path}")


# -------------------------- CLI --------------------------

def parse_args():
    p = argparse.ArgumentParser()
    sub = p.add_subparsers(dest="cmd", required=True)

    pc = sub.add_parser("capture", help="ROS2 capture: press 's' to save image + joint_states (+ TF base->tool)")
    pc.add_argument("--image_topic", type=str, default="/camera/image_raw")
    pc.add_argument("--joint_topic", type=str, default="/joint_states")
    pc.add_argument("--base_frame", type=str, default="base_link")
    pc.add_argument("--tool_frame", type=str, default="tool0")
    pc.add_argument("--output_dir", type=str, required=True)
    pc.add_argument("--intrinsics_yaml", type=str, default=None)
    pc.add_argument("--squares_x", type=int, default=8)
    pc.add_argument("--squares_y", type=int, default=11)
    pc.add_argument("--square_mm", type=float, default=15.0)
    pc.add_argument("--marker_mm", type=float, default=11.0)
    pc.add_argument("--min_charuco_corners", type=int, default=10)
    pc.add_argument("--dict_lock_after", type=int, default=10)

    ph = sub.add_parser("handeye", help="Offline hand-eye from captured dataset")
    ph.add_argument("--output_dir", type=str, required=True)
    ph.add_argument("--intrinsics_yaml", type=str, required=True)
    ph.add_argument("--squares_x", type=int, default=8)
    ph.add_argument("--squares_y", type=int, default=11)
    ph.add_argument("--square_mm", type=float, default=15.0)
    ph.add_argument("--marker_mm", type=float, default=11.0)
    ph.add_argument("--min_charuco_corners", type=int, default=10)
    ph.add_argument("--method", type=str, default="tsai",
                    choices=["tsai", "park", "horaud", "andreff", "daniilidis"])
    ph.add_argument("--dict_mode", type=str, default="auto_4x4",
                    help="auto_4x4 or DICT_4X4_50/100/250/1000")

    return p.parse_args()

def main():
    args = parse_args()
    if args.cmd == "capture":
        rclpy.init()
        node = CaptureNode(args)
        try:
            rclpy.spin(node)
        finally:
            try:
                cv2.destroyAllWindows()
            except Exception:
                pass
            node.destroy_node()
            rclpy.shutdown()

    elif args.cmd == "handeye":
        run_handeye_offline(
            output_dir=Path(args.output_dir),
            intrinsics_yaml=Path(args.intrinsics_yaml),
            squares_x=args.squares_x,
            squares_y=args.squares_y,
            square_mm=args.square_mm,
            marker_mm=args.marker_mm,
            min_charuco_corners=args.min_charuco_corners,
            method=args.method,
            dict_mode=args.dict_mode
        )
    else:
        raise RuntimeError("Unknown command")

if __name__ == "__main__":
    main()

"""
python3 ur5e_charuco_handeye_ros2.py capture \
  --image_topic /my_camera/pylon_ros2_camera_node/image_raw \
  --joint_topic /joint_states \
  --base_frame base_link \
  --tool_frame tool0 \
  --intrinsics_yaml /home/MA_SmartGrip/Smartgrip/calib_result/ost.yaml \
  --output_dir /home/MA_SmartGrip/Smartgrip/calib_result/cali

python3 ur5e_charuco_handeye_ros2.py handeye \
  --output_dir /home/MA_SmartGrip/Smartgrip/calib_result/cali \
  --intrinsics_yaml /home/MA_SmartGrip/Smartgrip/calib_result/ost.yaml \
  --method tsai
"""